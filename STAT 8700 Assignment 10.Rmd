---
title: "STAT 8700 Homework 10"
author: "Brian Detweiler"
date: "Tuesday, November 22th, 2016"
header-includes:
  - \usepackage{color}
  - \usepackage{xcolor}
  - \usepackage{soul}
  - \usepackage{hyperref}
  
output: pdf_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='Figs/',
                      echo=TRUE, warning=FALSE, message=FALSE)
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
library(rstan)
library(rjags)
source("DBDA2Eprograms/DBDA2E-utilities.R")

```
# 1. Consider the data presented in Table 7.3

```{r}
blue.earth <- c(5.0, 13.0, 7.2, 6.8, 12.8,  5.8,  9.5, 6.0, 3.8,  14.3, 1.8,  6.9, 4.7, 9.5)
blue.earth.level <- c(0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0)
clay <- c(0.9, 12.9, 2.6, 3.5, 26.6,  1.5, 13.0, 8.8, 19.5,  2.5, 9.0, 13.1, 3.6, 6.9)
clay.level <- c(1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1)
goodhue <-    c(14.3, 6.9, 7.6, 9.8,  2.6, 43.5,  4.9, 3.5,  4.8,  5.6, 3.5,  3.9, 6.7)
goodhue.level <- c(0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0)
radon.df <- cbind(blue.earth, blue.earth.level, clay, clay.level, goodhue, goodhue.level)
radon.df <- as.data.frame(radon.df)
radon.df

basements.blue.earth <- ((1 + blue.earth.level) %% 2)
basements.clay <- ((1 + clay.level) %% 2)
basements.goodhue <- ((1 + goodhue.level) %% 2)

basement.data <- data.frame(y=sum(basements.blue.earth), N=length(basements.blue.earth))
basement.data <- rbind(basement.data, data.frame(y=sum(basements.clay), N=length(basements.clay)))
basement.data <- rbind(basement.data, data.frame(y=sum(basements.goodhue), N=length(basements.goodhue)))
basement.data
```

## (a) Let $\theta_1$, $\theta_2$, and $\theta_3$ represent the proportion of houses that have basements in Blue Earth, Clay, and Goodhue counties respectively. Fit a hierarchical model to the data, and use it to obtain posterior summaries for $\theta_1$, $\theta_2$, and $\theta_3$.

```{r}

# Log Posterior (u, v space)
log.post2 <- function(u, v) {
  
  basements <- basement.data$y
  houses <- basement.data$N
  alpha <- exp(u + v) / (1 + exp(u))
  beta <- exp(v) / (1 + exp(u))
  ldens <- 0
  
  # Loop over each of the 71 experiments
  for(i in 1:length(houses)) {
    
    # There is no gamma function in R - have to use Log Gamma, so the density is logged
    # This is why it's addative rather than multiplicative
    # basements[i] is the same as y_i
    # houses[i] is the same as n_i
    ldens <- (ldens
             + (lgamma(alpha + beta) + lgamma(alpha + basements[i]) + lgamma(beta + houses[i] - basements[i]))
             - (lgamma(alpha) + lgamma(beta) + lgamma(alpha + beta + houses[i])))
  }

  # Return the final posterior density, which is still in logged form
  ldens - 5 / 2 * log(alpha + beta) + log(alpha) + log(beta)
}

# Just defines the size of each contour: 0.05, 0.15, 0.25, ..., 0.95
contours <- seq(0.05, 0.95, 0.1)

# Do the same steps as above, but refine the grid space
# Also, I changed the length to 200, because 2001 was slowing my computer to a crawl
u2 <- seq(-4, 4, length = 200)
v2 <- seq(-5, 13, length = 200)
logdens2 <- outer(u2, v2, log.post2)
# dens2 is a 200x200 matrix of probabilities for the u2, v2 values of alpha and beta
# For instance, u2[1] = -2.3, and v2[1] = 1. dens2[1, 1] = 1.978023e-14
# This is equivalent to saying p(alpha = -2.3, beta = 1) = 1.978023e-14
dens2 <- exp(logdens2 - max(logdens2))

fileName <- "Assignment_10_1_a"

modelString ="
model {

  for (j in 1:count) {
    y[j] ~ dbin(theta[j], N[j])
    theta[j] ~ dbeta(alpha, beta)
  }

  lnx <- log(alpha / beta)
  lny <- log(alpha + beta)

  alpha <- u / pow(v, 2)
  beta <- (1 - u) / pow(v, 2)

  u ~ dunif(0, 1)
  v ~ dunif(0, 1)
}
"

writeLines(modelString, con=fileName)

basementsModel = jags.model(file=fileName, 
                             data=list(y=basement.data$y,
                                       N=basement.data$N, 
                                       count=length(basement.data$N)),
                             n.chains=4)

update(basementsModel, n.iter=10000)


basementsSamples <- coda.samples(basementsModel, 
                                 n.iter=200000, 
                                 variable.names=c("alpha", "beta", "theta", "y", "lnx", "lny"), 
                                 thin=20)

basementsSamples.M <- as.matrix(basementsSamples)
summary(basementsSamples.M[,"theta[1]"])
summary(basementsSamples.M[,"theta[2]"])
summary(basementsSamples.M[,"theta[3]"])

contour(u2, v2, dens2, levels = contours, drawlabels = FALSE, xlim=c(-2, 4), ylim=c(-5, 13))
points(basementsSamples.M[,"lnx"], basementsSamples.M[,"lny"], col="red", pch=".", xlim=c(-2, 4), ylim=c(-5, 13))

hist(basementsSamples.M[,"theta[1]"], breaks=100, freq=F, col=rgb(0, 0, 1, .5))
hist(basementsSamples.M[,"theta[2]"], breaks=100, freq=F, col=rgb(1, 0, 0, .25), add=T)
hist(basementsSamples.M[,"theta[3]"], breaks=100, freq=F, col=rgb(0, 1, 0, .25), add=T)

```


## (b) Fit a linear regression to the natural log of the radon measurements, with indicator variables for the three counties and for weather a measurement was recorded on the first floor or basement, do not include an intercept term. Present posterior summaries for parameters and summarize your posterior inferences in non-technical terms (int, for each parameter $\beta$, what does $e^{\beta}$ represent?)

```{r}

radon.linreg <- data.frame(radon=log(radon.df$blue.earth), 
                           basement=as.numeric(!as.logical(radon.df$blue.earth.level)),
                           blue.earth=rep(1, length(radon.df$blue.earth)), 
                           clay=rep(0, length(radon.df$blue.earth)), 
                           goodhue=rep(0, length(radon.df$blue.earth)))

radon.linreg <- rbind(radon.linreg,
                      data.frame(radon=log(radon.df$clay), 
                           basement=as.numeric(!as.logical(radon.df$clay.level)),
                           blue.earth=rep(0, length(radon.df$clay)), 
                           clay=rep(1, length(radon.df$clay)), 
                           goodhue=rep(0, length(radon.df$clay))))
                      
radon.linreg <- rbind(radon.linreg,
                      data.frame(radon=log(radon.df$goodhue), 
                           basement=as.numeric(!as.logical(radon.df$goodhue.level)),
                           blue.earth=rep(0, length(radon.df$goodhue)), 
                           clay=rep(0, length(radon.df$goodhue)), 
                           goodhue=rep(1, length(radon.df$goodhue))))
                      
radon.linreg

fileName <- "Assignment_10_1_b"

modelString ="
model {

  for (j in 1:count) {
    y[j] ~ dnorm(mu[j], tau)
    mu[j] <- beta[1] * basement[j] + beta[2] * blueearth[j] + beta[3] * clay[j] + beta[4] * goodhue[j]
  }

  yclay ~ dnorm(beta[1], tau)

  # Prior for beta
  for(j in 1:4){
    beta[j] ~ dnorm(0,0.0001)
  }

  # Prior for the inverse variance
  tau   ~ dgamma(0.01, 0.01)

}
"

writeLines(modelString, con=fileName)

radonModel = jags.model(file=fileName, 
                             data=list(y=radon.linreg$radon,
                                       basement=radon.linreg$basement,
                                       blueearth=radon.linreg$blue.earth,
                                       clay=radon.linreg$clay,
                                       goodhue=radon.linreg$goodhue,
                                       count=length(radon.linreg$radon)),
                             n.chains=4)

update(radonModel, n.iter=10000)


radonSamples <- coda.samples(radonModel, 
                                 n.iter=1000000, 
                                 variable.names=c("beta", "yclay"),
                                 thin=50)
summary(radonSamples)
diagMCMC(codaObject = radonSamples)
radonSamples.M <- as.matrix(radonSamples)

summary(radonSamples.M)

```

$\beta_1$ represents whether the measurement was taken in a basement or not. It is clear that having a basement has a positive effect on $y$.

$\beta_2, \beta_3, \beta_4$ represents which county the measurement was taken in.

## (c) Suppose another house is sampled at random from Clay County, simulate values from the posterior predictive distribution for its radon measurements anf give an 95\% predictive interval. Express the interval of the original unlogged scale. (Hint: You must consider whether or not the randomly chosen house has a basement)

```{r}
yclay.quant <- quantile(exp(radonSamples.M[, "yclay"]), probs = c(0.025, 0.975))
hist(exp(radonSamples.M[,"yclay"]), breaks=100, freq=F, xlim=c(0, 20))
abline(v=c(yclay.quant[[1]], yclay.quant[[2]]), col="red")

beta1.quant <- quantile(exp(radonSamples.M[, "beta[1]"]), probs = c(0.025, 0.975))
hist(exp(radonSamples.M[,"beta[1]"]), breaks=100, freq=F, xlim=c(0, 5))
abline(v=c(beta1.quant[[1]], beta1.quant[[2]]), col="red")
```

\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak

# 2. The file \texttt{drinks.txt} contains the amount of time needed by a company employee to refill an automatic vending machine. For each refill, the number of cases of product and the distance walked (in feet) is also recorded.

```{r}
drinks <- read.table('drinks.txt', header=TRUE)
drinks$Intercept <- rep(1, length(drinks$Time))
drinks
```

## (a) Fit a linear regression model for the time taken, with number of cases and distance walked as explanatory variables (include an intercept term).

```{r}


fileName <- "Assignment_10_2_a"

modelString ="
model {

  for (j in 1:count) {
    y[j] ~ dnorm(mu[j], tau)
    
    mu[j] <- beta[1] * x1[j] + beta[2] * x2[j] + beta[3] * x3[j]

  }

  # Prior for beta
  for(j in 1:3){
    beta[j] ~ dnorm(0,0.0001)
  }

  # Prior for the inverse variance
  tau ~ dgamma(0.01, 0.01)

  # Predictive values
  ypred ~ dnorm(muavg, tau)
  muavg <- beta[1] * x1avg * beta[2] * x2avg + beta[3] * x3avg
  
  # For RB2   
  Svar <- pow(sd(y), 2)
  sigma2 <- 1 / tau

  RB2 <- 1 - (sigma2 / Svar)
}
"

writeLines(modelString, con=fileName)

drinksModel = jags.model(file=fileName, 
                             data=list(y = drinks$Time,
                                       x1 = drinks$Intercept,
                                       x2 = drinks$Distance,
                                       x3 = drinks$Cases,
                                       x1avg = mean(drinks$Intercept),
                                       x2avg = mean(drinks$Distance),
                                       x3avg = mean(drinks$Cases),
                                       count = length(drinks$Time)),
                             n.chains=4)

update(drinksModel, n.iter=10000)


drinksSamples <- coda.samples(drinksModel,
                                 n.iter=1000000, 
                                 variable.names=c("beta", "RB2", "Svar", "sigma2", "ypred"),
                                 thin=50)
diagMCMC(codaObject = drinksSamples)
drinksSamples.M <- as.matrix(drinksSamples)

rb2 <- quantile(drinksSamples.M[,"RB2"], probs = c(0.025, 0.975))
summary(drinksSamples.M)
ypredCI <- quantile(drinksSamples.M[, "ypred"], probs = c(0.025, 0.975))

```

## (b) In Classical Statistics, one way the quality of a regression model can be analyzed is by calculating something called the $AdjustedR^2$ value, it is basically the pro-portion of variation in the response variable that is explained by the explanatory variables, adjusted for the number of variables. Obviously, the closer this number is to 1, the better. The Bayesian equivalent R2B is defined as

$$
\begin{split}
  R_B^2 &= 1 - \frac{\sigma^2}{S_Y^2}
\end{split}
$$

## where $\sigma^2$ is the variance of the regression model and $s_Y^2$ is the sample variance of the response variable data. Note that since in the Bayesian framework $\sigma^2$ is a random variable, so is $R_B^2$. Obtain a 95\% credible interval for $R_B^2$. Does it seem like the model is a good for the data?

The CI for the $R_B^2$ for this model is (`r rb2[[1]]`, `r rb2[[2]]`), which indicates that the model is a good fit.

## (c) Obtain a 95\% predictive interval for how long it would take to restock the vending machine if the number of cases and distance were at their average (mean) values.

```{r}
hist(drinksSamples.M[, "ypred"], breaks=100, freq=F)
ypredCI <- quantile(drinksSamples.M[, "ypred"], probs = c(0.025, 0.975))
ypredCI
abline(v=c(ypredCI[[1]], ypredCI[[2]]), col="red")
```


\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak

# 3. Revisit the data in Question 1. Fit a Two-Way ANOVA to the natural log of the radon measurements. For each county in separately, construct a 95\% credible interval for the difference between the average (unlogged) radon measurement in houses with basements and in houses without basements. Test the hypothesis that the average radon measurement in houses with basements is greater than in houses without basements.


\begin{flushright}
  $\blacksquare$
\end{flushright}

\pagebreak